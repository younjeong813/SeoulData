import streamlit as st
from gtts import gTTS
import speech_recognition as sr
import os
import io
import numpy as np
from pdf_generator import create_pdf
from CV_generator import generate_cv_with_ai  # CV ìƒì„± í•¨ìˆ˜ ì„í¬íŠ¸

# Streamlit ì•± ì„¤ì •
st.set_page_config(
    page_title="Azure AI ê¸°ë°˜ ì´ë ¥ì„œ ì‘ì„±",
    page_icon="ğŸ¤",
    layout="wide",
)

st.title("ğŸ¤ OpenAI ê¸°ë°˜ ìŒì„± ì´ë ¥ì„œ ì‘ì„±")
st.write("ê° ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”. ìŒì„± ì…ë ¥ ë˜ëŠ” í…ìŠ¤íŠ¸ ì…ë ¥ì„ í†µí•´ ì‘ì„± ê°€ëŠ¥í•©ë‹ˆë‹¤.")

# ì‚¬ìš©ì ì…ë ¥ ë°ì´í„° ì €ì¥
if "page" not in st.session_state:
    st.session_state.page = 1  # ì´ˆê¸° í˜ì´ì§€ ì„¤ì •

if "user_data" not in st.session_state:
    st.session_state.user_data = {}

if "last_audio_played" not in st.session_state:
    st.session_state.last_audio_played = None

if "generated_cv" not in st.session_state:
    st.session_state.generated_cv = None  # ìƒì„±ëœ CV ë°ì´í„°

# ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
questions = [
    ("ì´ë¦„", "ì´ë¦„ì´ ë¬´ì—‡ì¸ê°€ìš”?"),
    ("ìƒë…„ì›”ì¼", "ìƒë…„ì›”ì¼ì´ ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”?"),
    ("ì—°ë½ì²˜", "ì—°ë½ì²˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"),
    ("ì£¼ì†Œ", "í˜„ì¬ ê±°ì£¼ì§€ëŠ” ì–´ë””ì¸ê°€ìš”? ì£¼ì†Œë¥¼ ë§ì”€í•´ì£¼ì„¸ìš”."),
    ("ìµœì¢…í•™ë ¥", "ë§ˆì§€ë§‰ìœ¼ë¡œ ì¡¸ì—…í•œ í•™êµì™€ ì „ê³µì„ ë§ì”€í•´ì£¼ì„¸ìš”."),
    ("ê²½ë ¥", "ì§€ê¸ˆê¹Œì§€ ì–´ë–¤ ì§ì—…(ì§ë¬´)ì„ í•˜ì…¨ë‚˜ìš”?"),
    ("ê·¼ë¬´ê¸°ê°„", "ê° ì§ì—…ì—ì„œ ê·¼ë¬´í•œ ê¸°ê°„ì„ ì•Œë ¤ì£¼ì„¸ìš”."),
    ("ì£¼ìš” ì—…ë¬´", "ì£¼ìš” ì—…ë¬´ë‚˜ ì—­í• ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?"),
    ("ê°•ì ", "ê°•ì ìœ¼ë¡œ ëŠê¼ˆë˜ ë¶€ë¶„ì„ ë§ì”€í•´ì£¼ì„¸ìš”."),
    ("ìê²©ì¦", "ì–´ë–¤ ìê²©ì¦ì„ ë³´ìœ í•˜ê³  ê³„ì‹ ê°€ìš”?"),
    ("ì·¨ë¯¸", "ì—¬ê°€ì‹œê°„ì— ì£¼ë¡œ ì–´ë–¤ ì·¨ë¯¸ë¥¼ ì¦ê¸°ì‹œë‚˜ìš”?"),
    ("ì„±ê²©", "ìì‹ ì˜ ì„±ê²©ì´ë‚˜ ì¥ì ì— ëŒ€í•´ì„œ ë§ì”€í•´ì£¼ì„¸ìš”."),
]


# í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
def text_to_speech(text, lang="ko"):
    """
    í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³  ë©”ëª¨ë¦¬ì—ì„œ ì§ì ‘ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    :param text: ë³€í™˜í•  í…ìŠ¤íŠ¸
    :param lang: ìŒì„± ì–¸ì–´ (ê¸°ë³¸ê°’: 'ko')
    :return: BytesIO ê°ì²´ë¡œ ë°˜í™˜ëœ MP3 ë°ì´í„°
    """
    tts = gTTS(text=text, lang=lang)
    audio_data = io.BytesIO()  # ë©”ëª¨ë¦¬ íŒŒì¼ ìƒì„±
    tts.write_to_fp(audio_data)  # MP3 ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ íŒŒì¼ì— ì €ì¥
    audio_data.seek(0)  # ë©”ëª¨ë¦¬ íŒŒì¼ì˜ ì‹œì‘ ìœ„ì¹˜ë¡œ ì´ë™
    return audio_data


# ìŒì„± ì…ë ¥ ì²˜ë¦¬
def recognize_speech():
    recognizer = sr.Recognizer()
    try:
        with sr.Microphone() as source:
            st.write("ìŒì„± ì…ë ¥ ì¤‘... ë§ì”€í•´ì£¼ì„¸ìš”!")
            audio = recognizer.listen(source, timeout=5)
            text = recognizer.recognize_google(audio, language="ko-KR")
            return text
    except sr.UnknownValueError:
        st.error("âŒ ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return ""
    except sr.RequestError as e:
        st.error(f"âŒ ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {e}")
        return ""


# í˜ì´ì§€ ì „í™˜ í•¨ìˆ˜
def next_page():
    st.session_state.page += 1


def previous_page():
    st.session_state.page -= 1


def submit_resume():
    st.session_state.page = "preview"


# CSS ì¶”ê°€: í…ìŠ¤íŠ¸ ì…ë ¥ í•„ë“œì™€ Audio Player í¬ê¸° ì¡°ì •
st.markdown(
    """
    <style>
    /* í…ìŠ¤íŠ¸ ì…ë ¥ í•„ë“œ í¬ê¸° ì¡°ì • */

    .centered {
        text-align: center; /* í…ìŠ¤íŠ¸ ì¤‘ì•™ ì •ë ¬ */
    }

    </style>
    """,
    unsafe_allow_html=True,
)


# ì§ˆë¬¸ í˜ì´ì§€
def question_page():
    current_index = st.session_state.page - 1
    total_questions = len(questions)

    if current_index < 0 or current_index >= len(questions):
        st.error("ìœ íš¨í•˜ì§€ ì•Šì€ í˜ì´ì§€ì…ë‹ˆë‹¤.")
        return

    key, question = questions[current_index]

    # ì§ˆë¬¸ í…ìŠ¤íŠ¸ ê°€ìš´ë° ì •ë ¬
    st.markdown(
        f"<h2 style='text-align: center;'>ì§ˆë¬¸ {current_index + 1} : {question}</h2>",
        unsafe_allow_html=True,
    )

    # ì§ˆë¬¸ ìŒì„± ì¶œë ¥ (í˜ì´ì§€ ë¡œë“œ ì‹œ ìë™)
    if st.session_state.last_audio_played != st.session_state.page:
        audio_file = text_to_speech(question)  # ìŒì„±ì„ ìƒì„±í•˜ì—¬ íŒŒì¼ ì €ì¥
        st.audio(audio_file, format="audio/mp3", start_time=0)  # ê¸°ë³¸ ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´
        st.session_state.last_audio_played = st.session_state.page

    # í…ìŠ¤íŠ¸ ì…ë ¥ í•„ë“œ
    unique_key = f"question_{current_index}"  # ê³ ìœ í•œ í‚¤ ìƒì„±
    st.session_state.user_data[key] = st.text_input(
        "",
        value=st.session_state.user_data.get(key, ""),
        key=unique_key,  # ê³ ìœ í•œ í‚¤ ì‚¬ìš©
    )

    # ìŒì„± ì…ë ¥ ë²„íŠ¼
    col1, col2, col3 = st.columns([5, 4, 1])  # ë²„íŠ¼ì„ ê°€ìš´ë° ë°°ì¹˜
    with col2:
        # Streamlit ê¸°ë³¸ ë²„íŠ¼ì„ ì‚¬ìš©
        if st.button("ğŸ™ï¸", key=f"audio_{current_index}"):
            recognized_text = recognize_speech()  # ìŒì„± ì…ë ¥ ìˆ˜í–‰
            if recognized_text:
                st.session_state.user_data[key] = recognized_text
                st.success("ìŒì„±ì´ ì„±ê³µì ìœ¼ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤!")

    # ì—¬ë°± ì¶”ê°€
    st.markdown("<div style='margin-bottom: 200px;'></div>", unsafe_allow_html=True)

    col1, col2, col3 = st.columns([1, 8, 1])  # ê°„ê²© ì¡°ì •
    with col1:
        if current_index > 0:
            st.button(
                "ì´ì „",
                on_click=lambda: st.session_state.update(
                    page=st.session_state.page - 1
                ),
            )
    with col3:
        if current_index < total_questions - 1:
            st.button(
                "ë‹¤ìŒ",
                on_click=lambda: st.session_state.update(
                    page=st.session_state.page + 1
                ),
            )
        else:
            st.button("ì œì¶œ", on_click=lambda: st.session_state.update(page="preview"))

    # ì§„í–‰ë°” ì¶”ê°€
    progress = (current_index + 1) / total_questions
    st.progress(progress)


# ë¯¸ë¦¬ë³´ê¸° í˜ì´ì§€
def preview_page():
    st.title("ğŸ“„ ì´ë ¥ì„œ ë¯¸ë¦¬ë³´ê¸°")

    # ì…ë ¥ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ CV ìƒì„±
    if st.session_state.generated_cv is None:
        answer_sheet = st.session_state.user_data
        st.session_state.generated_cv = generate_cv_with_ai(answer_sheet)

    # ìƒì„±ëœ CV ì¶œë ¥
    st.write("### í•´ë‹¹ ì •ë³´ê°€ ë§ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.markdown(f"\n{st.session_state.generated_cv}\n")

    # ì‚¬ì§„ ì—…ë¡œë“œ
    uploaded_photo = st.file_uploader(
        "ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”:", type=["jpg", "jpeg", "png"]
    )

    # ì—…ë¡œë“œëœ ì‚¬ì§„ í™•ì¸
    if uploaded_photo:
        uploaded_photo_path = os.path.join("output", "uploaded_photo.jpg")
        with open(uploaded_photo_path, "wb") as f:
            f.write(uploaded_photo.getbuffer())  # ì—…ë¡œë“œëœ ì‚¬ì§„ ì €ì¥
        st.image(uploaded_photo, caption="ì—…ë¡œë“œëœ ì‚¬ì§„", use_container_width=True)
    else:
        uploaded_photo_path = None

    # PDF ì €ì¥ ë²„íŠ¼
    if st.button("PDFë¡œ ì €ì¥"):
        pdf_path = create_pdf(
            st.session_state.generated_cv, uploaded_photo_path
        )  # ìƒì„±ëœ CVë¡œ PDF ìƒì„±
        st.success("PDFê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
        with open(pdf_path, "rb") as pdf_file:
            st.download_button(
                "ğŸ“¥ PDF ë‹¤ìš´ë¡œë“œ",
                data=pdf_file,
                file_name="resume.pdf",
                mime="application/pdf",
            )

    # ì´ì „ ë²„íŠ¼
    if st.button("ì´ì „"):
        st.session_state.page = len(questions)


# í˜ì´ì§€ ë Œë”ë§
if isinstance(st.session_state.page, int) and st.session_state.page <= len(questions):
    question_page()
elif st.session_state.page == "preview":
    preview_page()
else:
    st.error("ìœ íš¨í•˜ì§€ ì•Šì€ í˜ì´ì§€ì…ë‹ˆë‹¤.")
